{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jYysdyb-CaWM"
   },
   "source": [
    "# モデルトレーニングの基礎 - 服装画像の基本分類"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "__source: https://www.tensorflow.org/tutorials/keras/classification__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FbVhjPpzn6BM"
   },
   "source": [
    "このノートブックの例では、スニーカーやシャツなどの衣類の画像を分類するためにニューラル ネットワーク モデルをトレーニングします。詳細をすべて理解していなくても大丈夫です。これは、完全な TensorFlow プログラムのテンポの速い概要であり、詳細については説明しながら進めていきます。ご存じなかった方のために説明しますと、TensorFlow は、機械学習と深層学習で使用されるデータフローと微分可能プログラミングのためのオープンソース ソフトウェア ライブラリです。機械学習および深層学習モデルを構築およびデプロイするための柔軟で効率的なプラットフォームを提供します。\n",
    "\n",
    "このガイドでは、TensorFlow でモデルを構築およびトレーニングするための高レベル API である [tf.keras](https://www.tensorflow.org/guide/keras) を使用します。 \n",
    "\n",
    "それでは、必要なライブラリをインポートすることから始めましょう。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dzLKpmZICaWN",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# TensorFlow と tf.keras\n",
    "import tensorflow as tf\n",
    "\n",
    "# ヘルパーライブラリ\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yR0EdgrLCaWR"
   },
   "source": [
    "## ファッション MNIST データセットをインポート"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DLdCchMdCaWQ"
   },
   "source": [
    "この例では、10 カテゴリの 70,000 個のグレースケール画像を含む [Fashion MNIST](https://github.com/zalandoresearch/fashion-mnist) データセットを使用します。以下に示すように、画像は個々の衣料品を低解像度 (28 x 28 ピクセル) で示しています。\n",
    "\n",
    "<table>\n",
    "  <tr><td>\n",
    "    <img src=\"https://tensorflow.org/images/fashion-mnist-sprite.png\"\n",
    "         alt=\"Fashion MNIST sprite\"  width=\"600\">\n",
    "  </td></tr>\n",
    "  <tr><td align=\"center\">\n",
    "    <b>Figure 1.</b> <a href=\"https://github.com/zalandoresearch/fashion-mnist\">Fashion-MNIST samples</a> (by Zalando, MIT License).<br/>&nbsp;\n",
    "  </td></tr>\n",
    "</table>\n",
    "\n",
    "ファッション MNIST は、古典的な [MNIST](http://yann.lecun.com/exdb/mnist/) データセットのドロップイン代替として意図されており、多くの場合、機械学習プログラムの「Hello, World」として使用されます。MNIST データセットには、ここで使用する衣料品の形式と同じ形式の手書きの数字 (0、1、2 など) の画像が含まれています。\n",
    "\n",
    "このガイドでは、ファッション MNIST を多様性のために使用しています。これは、通常の MNIST よりも少し難しい問題であるためです。どちらのデータセットも比較的小さく、アルゴリズムが期待どおりに機能することを検証するために使用されます。これらは、コードのテストとデバッグの良い出発点となります。\n",
    "\n",
    "ここでは、60,000 枚の画像を使用してネットワークをトレーニングし、10,000 枚の画像を使用してネットワークが画像の分類をどの程度正確に学習したかを評価します。 TensorFlow から直接 Fashion MNIST にアクセスできます。 インポートして [Fashion MNIST データをロード](https://www.tensorflow.org/api_docs/python/tf/keras/datasets/fashion_mnist/load_data) を使用してTensorFlow から直接データをロードできます。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7MqDQO0KCaWS",
    "tags": []
   },
   "outputs": [],
   "source": [
    "fashion_mnist = tf.keras.datasets.fashion_mnist\n",
    "\n",
    "(train_images, train_labels), (test_images, test_labels) = fashion_mnist.load_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "t9FDsUlxCaWW"
   },
   "source": [
    "データセットをロードすると、4 つの NumPy 配列が返されます。\n",
    "\n",
    "*`train_images` 配列と `train_labels` 配列は *トレーニング セット* 、つまりモデルが学習するために使用するデータです。\n",
    "*モデルは、 *テスト セット* 、`test_images` および `test_labels` 配列に対してテストされています。\n",
    "\n",
    "画像は 28x28 の NumPy 配列で、ピクセル値の範囲は 0 ～ 255 です。 *ラベル* は 0 ～ 9 の範囲の整数の配列です。これらは、画像が表す衣類の *クラス* に対応します。\n",
    "\n",
    "<table>\n",
    "  <tr>\n",
    "    <th>Label</th>\n",
    "    <th>Class</th>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>0</td>\n",
    "    <td>T-shirt/top</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>1</td>\n",
    "    <td>Trouser</td>\n",
    "  </tr>\n",
    "    <tr>\n",
    "    <td>2</td>\n",
    "    <td>Pullover</td>\n",
    "  </tr>\n",
    "    <tr>\n",
    "    <td>3</td>\n",
    "    <td>Dress</td>\n",
    "  </tr>\n",
    "    <tr>\n",
    "    <td>4</td>\n",
    "    <td>Coat</td>\n",
    "  </tr>\n",
    "    <tr>\n",
    "    <td>5</td>\n",
    "    <td>Sandal</td>\n",
    "  </tr>\n",
    "    <tr>\n",
    "    <td>6</td>\n",
    "    <td>Shirt</td>\n",
    "  </tr>\n",
    "    <tr>\n",
    "    <td>7</td>\n",
    "    <td>Sneaker</td>\n",
    "  </tr>\n",
    "    <tr>\n",
    "    <td>8</td>\n",
    "    <td>Bag</td>\n",
    "  </tr>\n",
    "    <tr>\n",
    "    <td>9</td>\n",
    "    <td>Ankle boot</td>\n",
    "  </tr>\n",
    "</table>\n",
    "\n",
    "各イメージは 1 つのラベルにマッピングされます。 *クラス名* はデータセットに含まれていないため、後で画像をプロットするときに使用するためにここに保存します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "IjnLH5S2CaWx",
    "tags": []
   },
   "outputs": [],
   "source": [
    "class_names = ['T-shirt/top', 'Trouser', 'Pullover', 'Dress', 'Coat',\n",
    "               'Sandal', 'Shirt', 'Sneaker', 'Bag', 'Ankle boot']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Brm0b_KACaWX"
   },
   "source": [
    "## データの探索\n",
    "\n",
    "モデルをトレーニングする前に、データセットの形式を調べてみましょう。以下は、トレーニング セットに 60,000 個の画像があり、各画像が 28 x 28 ピクセルで表されていることを示しています。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zW5k_xz1CaWX",
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_images.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cIAcvQqMCaWf"
   },
   "source": [
    "同様に、トレーニング セットには 60,000 のラベルがあります。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "TRFYHB2mCaWb",
    "tags": []
   },
   "outputs": [],
   "source": [
    "len(train_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YSlYxFuRCaWk"
   },
   "source": [
    "各ラベルは 0 から 9 までの整数です。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XKnCTHz4CaWg",
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TMPI88iZpO2T"
   },
   "source": [
    "テスト セットには 10,000 枚の画像があります。繰り返しますが、各画像は 28 x 28 ピクセルとして表されます。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2KFnYlcwCaWl",
    "tags": []
   },
   "outputs": [],
   "source": [
    "test_images.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rd0A0Iu0CaWq"
   },
   "source": [
    "テスト セットには 10,000 個の画像ラベルが含まれています。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "iJmPr5-ACaWn",
    "tags": []
   },
   "outputs": [],
   "source": [
    "len(test_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ES6uQoLKCaWr"
   },
   "source": [
    "## データの前処理\n",
    "\n",
    "ネットワークをトレーニングする前に、データを前処理する必要があります。トレーニング セットの最初の画像を調べると、ピクセル値が 0 ～ 255 の範囲にあることがわかります。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "m4VEw8Ud9Quh",
    "tags": []
   },
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.imshow(train_images[0])\n",
    "plt.colorbar()\n",
    "plt.grid(False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Wz7l27Lz9S1P"
   },
   "source": [
    "これらの値をニューラル ネットワーク モデルに入力する前に、0 から 1 の範囲にスケールします (これは標準的な正規化手順です)。これを行うには、値を 255 で割ります。トレーニング セットとテスト セットを同じ方法で前処理することが重要です。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bW5WzIPlCaWv",
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_images = train_images / 255.0\n",
    "\n",
    "test_images = test_images / 255.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ee638AlnCaWz"
   },
   "source": [
    "データが正しい形式であること、およびネットワークを構築してトレーニングする準備ができていることを確認するために、トレーニング セットの最初の 25 個の画像を表示し、各画像の下にクラス名を表示してみましょう。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "oZTImqg_CaW1",
    "tags": []
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,10))\n",
    "for i in range(25):\n",
    "    plt.subplot(5,5,i+1)\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "    plt.grid(False)\n",
    "    plt.imshow(train_images[i], cmap=plt.cm.binary)\n",
    "    plt.xlabel(class_names[train_labels[i]])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "59veuiEZCaW4"
   },
   "source": [
    "## モデルの構築\n",
    "\n",
    "ニューラル ネットワークを構築するには、モデルの層を構成してからモデルをコンパイルする必要があります。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Gxg1XGm0eOBy"
   },
   "source": [
    "### レイヤーの設定\n",
    "\n",
    "ニューラル ネットワークの基本的な構成要素は [*レイヤー*](https://www.tensorflow.org/api_docs/python/tf/keras/layers) です。レイヤーは、入力されたデータから表現を抽出します。これらの表現が当面の問題にとって意味のあるものであることを願っています。\n",
    "\n",
    "深層学習のほとんどは、単純なレイヤーを連鎖させて構成されています。 `tf.keras.layers.Dense` などのほとんどのレイヤーには、トレーニング中に学習されるパラメーターがあります。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9ODch-OFCaW4",
    "tags": []
   },
   "outputs": [],
   "source": [
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Flatten(input_shape=(28, 28)),\n",
    "    tf.keras.layers.Dense(128, activation='relu'),\n",
    "    tf.keras.layers.Dense(10)\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gut8A_7rCaW6"
   },
   "source": [
    "このネットワークの最初の層である `tf.keras.layers.Flatten` は、画像の形式を 2 次元配列 (28 x 28 ピクセル) から 1 次元配列 (28 * 28 = 784 ピクセル) に変換します。 ）。このレイヤーは、画像内のピクセルの行を積み上げずに並べるものと考えてください。この層には学習するパラメータがありません。データを再フォーマットするだけです。\n",
    "\n",
    "ピクセルが平坦化された後、ネットワークは 2 つの `tf.keras.layers.Dense` 層のシーケンスで構成されます。これらは密に接続された、または完全に接続されたニューラルの層です。最初の `Dense` 層には 128 個のノード (またはニューロン) があります。 2 番目 (最後の) 層は、長さ 10 のロジット配列を返します。各ノードには、現在の画像が 10 個のクラスのいずれかに属していることを示すスコアが含まれています。\n",
    "\n",
    "### モデルのコンパイル\n",
    "\n",
    "モデルをトレーニングする準備の前に、さらにいくつかの設定が必要です。これらは、モデルの [*compile*](https://www.tensorflow.org/api_docs/python/tf/keras/Model#compile) ステップ中に追加されます。\n",
    "\n",
    "* [*Loss function*](https://www.tensorflow.org/api_docs/python/tf/keras/losses) — これは、トレーニング中のモデルの精度を測定します。モデルを正しい方向に \"steer（誘導）\" するには、この関数を最小化する必要があります。\n",
    "* [*Optimizer*](https://www.tensorflow.org/api_docs/python/tf/keras/optimizers) — これは、表示されるデータとそのLoss functionに基づいてモデルが更新される方法です。\n",
    "* [*Metrics*](https://www.tensorflow.org/api_docs/python/tf/keras/metrics) - トレーニングとテストのステップを監視するために使用されます。次の例では、正しく分類された画像の割合である *accuracy（正確さ）* を使用します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Lhan11blCaW7",
    "tags": []
   },
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam',\n",
    "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qKF6uW-BCaW-"
   },
   "source": [
    "## モデルのトレーニング\n",
    "\n",
    "ニューラル ネットワーク モデルをトレーニングするには、次の手順が必要です。\n",
    "\n",
    "1. トレーニング データをモデルにフィードします。この例では、トレーニング データは `train_images` 配列と `train_labels` 配列内にあります。\n",
    "2. モデルは画像とラベルの関連付けを学習します。\n",
    "3. モデルにテスト セット (この例では `test_images` 配列) についての予測を行うように依頼します。\n",
    "4. 予測が `test_labels` 配列のラベルと一致することを確認します。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Z4P4zIV7E28Z"
   },
   "source": [
    "### モデルにデータをフィード\n",
    "\n",
    "トレーニングを開始するには、[`model.fit`](https://www.tensorflow.org/api_docs/python/tf/keras/Model#fit) メソッドを呼び出します。このメソッドは、モデルをトレーニングデータに \"fits\" させるため、このように呼ばれます。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xvwvpA64CaW_",
    "tags": []
   },
   "outputs": [],
   "source": [
    "model.fit(train_images, train_labels, epochs=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "W3ZVOhugCaXA"
   },
   "source": [
    "モデルがトレーニングされると、　LossとAccuracyのメトリクスが表示されます。このモデルは、トレーニング データで約 0.91 (または 91%) の精度に達します。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wCpr6DGyE28h"
   },
   "source": [
    "### 精度の評価\n",
    "\n",
    "次に、モデルがテスト データセットでどのようにふるまうのかを確認します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VflXLEeECaXC",
    "tags": []
   },
   "outputs": [],
   "source": [
    "test_loss, test_acc = model.evaluate(test_images,  test_labels, verbose=2)\n",
    "\n",
    "print('\\nTest accuracy:', test_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yWfgsmVXCaXG"
   },
   "source": [
    "テスト データセットの精度は、トレーニング データセットの精度よりもわずかに低いことがわかります。トレーニング精度とテスト精度の間のこのギャップは、 *overfitting（過学習）* を表します。過学習は、機械学習モデルが、トレーニング データよりも、これまでに見たことのない新しい入力に対してパフォーマンスが悪い場合に発生します。過学習モデルは、トレーニング データセット内のノイズと詳細を \"memorizes（記憶）\" し、新しいデータに対するモデルのパフォーマンスに悪影響を及ぼします。詳細については、以下を参照してください。\n",
    "*   [過学習のデモ](https://www.tensorflow.org/tutorials/keras/overfit_and_underfit?hl=ja#%E9%81%8E%E5%AD%A6%E7%BF%92%E3%81%AE%E3%83%87%E3%83%A2)\n",
    "*   [過学習防止の戦略](https://www.tensorflow.org/tutorials/keras/overfit_and_underfit?hl=ja#%E9%81%8E%E5%AD%A6%E7%BF%92%E9%98%B2%E6%AD%A2%E3%81%AE%E6%88%A6%E7%95%A5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "v-PyD1SYE28q"
   },
   "source": [
    "### 予測の実行\n",
    "\n",
    "モデルをトレーニングすると、それを使用していくつかの画像についての予測を行うことができます。\n",
    softmax レイヤーをアタッチして、モデルの線形出力 -  [logits](https://developers.google.com/machine-learning/glossary#logits) - を確率に変換すると、解釈が容易になります。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "DnfNA0CrQLSD",
    "tags": []
   },
   "outputs": [],
   "source": [
    "probability_model = tf.keras.Sequential([model, \n",
    "                                         tf.keras.layers.Softmax()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Gl91RPhdCaXI",
    "tags": []
   },
   "outputs": [],
   "source": [
    "predictions = probability_model.predict(test_images)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "x9Kk1voUCaXJ"
   },
   "source": [
    "ここで、モデルはテスト セット内の各画像のラベルを予測しました。最初の予測を見てみましょう。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3DmJEUinCaXK",
    "tags": []
   },
   "outputs": [],
   "source": [
    "predictions[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-hw1hgeSCaXN"
   },
   "source": [
    "予測は 10 個の数値の配列です。これらは、画像が 10 種類の衣服のそれぞれに対応しているというモデルの \"confidence（信頼度・自信）\" を表しています。どのラベルの信頼値が最も高いかを確認できます。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qsqenuPnCaXO",
    "tags": []
   },
   "outputs": [],
   "source": [
    "np.argmax(predictions[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "E51yS7iCCaXO"
   },
   "source": [
    "したがって、モデルは、この画像がアンクル ブーツ、つまり `class_names[9]` であると最も確信しています。テスト ラベルを調べると、この分類が正しいことがわかります。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Sd7Pgsu6CaXP",
    "tags": []
   },
   "outputs": [],
   "source": [
    "test_labels[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ygh2yYC972ne"
   },
   "source": [
    "予測をグラフ化するための 2 つのヘルパー関数を作成します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "DvYmmrpIy6Y1",
    "tags": []
   },
   "outputs": [],
   "source": [
    "def plot_image(i, predictions_array, true_label, img):\n",
    "  true_label, img = true_label[i], img[i]\n",
    "  plt.grid(False)\n",
    "  plt.xticks([])\n",
    "  plt.yticks([])\n",
    "\n",
    "  plt.imshow(img, cmap=plt.cm.binary)\n",
    "\n",
    "  predicted_label = np.argmax(predictions_array)\n",
    "  if predicted_label == true_label:\n",
    "    color = 'blue'\n",
    "  else:\n",
    "    color = 'red'\n",
    "\n",
    "  plt.xlabel(\"{} {:2.0f}% ({})\".format(class_names[predicted_label],\n",
    "                                100*np.max(predictions_array),\n",
    "                                class_names[true_label]),\n",
    "                                color=color)\n",
    "\n",
    "def plot_value_array(i, predictions_array, true_label):\n",
    "  true_label = true_label[i]\n",
    "  plt.grid(False)\n",
    "  plt.xticks(range(10))\n",
    "  plt.yticks([])\n",
    "  thisplot = plt.bar(range(10), predictions_array, color=\"#777777\")\n",
    "  plt.ylim([0, 1])\n",
    "  predicted_label = np.argmax(predictions_array)\n",
    "\n",
    "  thisplot[predicted_label].set_color('red')\n",
    "  thisplot[true_label].set_color('blue')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Zh9yABaME29S"
   },
   "source": [
    "### 予測の検証\n",
    "\n",
    "モデルをトレーニングすると、それを使用していくつかの画像についての予測を行うことができます。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "d4Ov9OFDMmOD"
   },
   "source": [
    "0 番目の画像、予測、予測配列を見てみましょう。正しい予測ラベルは青、不正確な予測ラベルは赤です。この数値は、予測されたラベルのパーセンテージ (100 のうち) を示します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "HV5jw-5HwSmO",
    "tags": []
   },
   "outputs": [],
   "source": [
    "i = 0\n",
    "plt.figure(figsize=(6,3))\n",
    "plt.subplot(1,2,1)\n",
    "plot_image(i, predictions[i], test_labels, test_images)\n",
    "plt.subplot(1,2,2)\n",
    "plot_value_array(i, predictions[i],  test_labels)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "12 番目の画像でも同じですが、予測に誤りがあります。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Ko-uzOufSCSe",
    "tags": []
   },
   "outputs": [],
   "source": [
    "i = 12\n",
    "plt.figure(figsize=(6,3))\n",
    "plt.subplot(1,2,1)\n",
    "plot_image(i, predictions[i], test_labels, test_images)\n",
    "plt.subplot(1,2,2)\n",
    "plot_value_array(i, predictions[i],  test_labels)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kgdvGD52CaXR"
   },
   "source": [
    "いくつかの画像とその予測をプロットしてみましょう。非常に自信がある場合でも、モデルが間違っている可能性があることに注意してください。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hQlnbqaw2Qu_",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 最初の X テスト イメージ、その予測ラベル、および真のラベルをプロットします。\n",
    "# 正しい予測を青、不正確な予測を赤で色付けします。\n",
    "num_rows = 5\n",
    "num_cols = 3\n",
    "num_images = num_rows*num_cols\n",
    "plt.figure(figsize=(2*2*num_cols, 2*num_rows))\n",
    "for i in range(num_images):\n",
    "  plt.subplot(num_rows, 2*num_cols, 2*i+1)\n",
    "  plot_image(i, predictions[i], test_labels, test_images)\n",
    "  plt.subplot(num_rows, 2*num_cols, 2*i+2)\n",
    "  plot_value_array(i, predictions[i], test_labels)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "R32zteKHCaXT"
   },
   "source": [
    "## トレーニングされたモデルの使用\n",
    "\n",
    "最後に、トレーニングされたモデルを使用して、単一の画像についての予測を行います。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "yRJ7JU7JCaXT",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# テスト データセットから画像を取得します。\n",
    "img = test_images[1]\n",
    "\n",
    "print(img.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vz3bVp21CaXV"
   },
   "source": [
    "`tf.keras` モデルは、サンプルの *バッチ* 、またはコレクションを一度に予測するように最適化されています。したがって、単一の画像を使用している場合でも、それをリストに追加する必要があります。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lDFh5yF_CaXW",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 画像を唯一のメンバーとしてバッチに追加します。\n",
    "img = (np.expand_dims(img,0))\n",
    "\n",
    "print(img.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EQ5wLTkcCaXY"
   },
   "source": [
    "次に、この画像の正しいラベルを予測します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "o_rzNSdrCaXY",
    "tags": []
   },
   "outputs": [],
   "source": [
    "predictions_single = probability_model.predict(img)\n",
    "\n",
    "print(predictions_single)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6Ai-cpLjO-3A",
    "tags": []
   },
   "outputs": [],
   "source": [
    "plot_value_array(1, predictions_single[0], test_labels)\n",
    "_ = plt.xticks(range(10), class_names, rotation=45)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cU1Y2OAMCaXb"
   },
   "source": [
    "`tf.keras.Model.predict` はリストのリスト (データのバッチ内の画像ごとに 1 つのリスト) を返します。バッチ内の (唯一の) 画像の予測を取得します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2tRmdq_8CaXb",
    "tags": []
   },
   "outputs": [],
   "source": [
    "np.argmax(predictions_single[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "そして、モデルは期待どおりにラベルを予測します。\n",
    "\n",
    "結果に満足したので、モデルを保存できます。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('my-model.keras')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YFc2HbEVCaXd"
   },
   "source": [
    "### これで、インストラクションに戻ります。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "##### Copyright 2018 The TensorFlow Authors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "# you may not use this file except in compliance with the License.\n",
    "# You may obtain a copy of the License at\n",
    "#\n",
    "# https://www.apache.org/licenses/LICENSE-2.0\n",
    "#\n",
    "# Unless required by applicable law or agreed to in writing, software\n",
    "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "# See the License for the specific language governing permissions and\n",
    "# limitations under the License."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title MIT License\n",
    "#\n",
    "# Copyright (c) 2017 François Chollet\n",
    "#\n",
    "# Permission is hereby granted, free of charge, to any person obtaining a\n",
    "# copy of this software and associated documentation files (the \"Software\"),\n",
    "# to deal in the Software without restriction, including without limitation\n",
    "# the rights to use, copy, modify, merge, publish, distribute, sublicense,\n",
    "# and/or sell copies of the Software, and to permit persons to whom the\n",
    "# Software is furnished to do so, subject to the following conditions:\n",
    "#\n",
    "# The above copyright notice and this permission notice shall be included in\n",
    "# all copies or substantial portions of the Software.\n",
    "#\n",
    "# THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\n",
    "# IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\n",
    "# FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL\n",
    "# THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\n",
    "# LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING\n",
    "# FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER\n",
    "# DEALINGS IN THE SOFTWARE."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "classification.ipynb",
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
